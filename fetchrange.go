package kafka

import (
	"math"
	"sort"
)

// fetchRange is a type carrying configurations for a fetch request.
type fetchRange struct {
	startOffset int64 // first offset of the range
	endOffset   int64 // last offset of the range (exclusive)
	minBytes    int64 // minimum byes that can be read in this range
	maxBytes    int64 // estimated maximum bytes that can be read in this range
}

// makeFetchRanges generates an optimal set of fetch operations to fetch the
// list of offsets passed as arguments while maintaining the ratio of unused
// bytes within the specified value.
func makeFetchRanges(maxUnusedRatio float64, offsets ...offset) []fetchRange {
	if len(offsets) == 0 {
		return nil
	}

	sortedOffsets := make([]offset, len(offsets))
	copy(sortedOffsets, offsets)

	sort.Slice(sortedOffsets, func(i, j int) bool {
		return sortedOffsets[i].value < sortedOffsets[j].value
	})

	// Compute the average size of a message based on what we know from the
	// offsets we were given. This is later used to estimate the number of bytes
	// between non-contiguous offsets.
	avgSize := int64(0)
	for _, off := range sortedOffsets {
		avgSize += off.size
	}
	avgSize /= int64(len(sortedOffsets))

	// Compute the number of bytes that we accept to waste based on the max
	// unused ratio and the estimated average size of a message.
	firstOffset := sortedOffsets[0].value
	lastOffset := sortedOffsets[len(sortedOffsets)-1].value

	maxUnusedBytes := avgSize * (lastOffset - firstOffset)
	maxUnusedBytes = int64(math.Round(float64(maxUnusedBytes) * maxUnusedRatio))

	// Fetch ranges are first generated by merging contiguous offsets into a
	// single range.
	fetchRanges := make([]fetchRange, 1, len(sortedOffsets)/3)
	fetchRanges[0] = fetchRange{
		startOffset: sortedOffsets[0].value,
		endOffset:   sortedOffsets[0].value + 1,
		minBytes:    sortedOffsets[0].size,
		maxBytes:    sortedOffsets[0].size,
	}

	for _, off := range sortedOffsets[1:] {
		r := &fetchRanges[len(fetchRanges)-1]

		if r.endOffset == off.value { // contiguous offsets
			r.endOffset++
			r.minBytes += off.size
			r.maxBytes += off.size
			continue
		}

		fetchRanges = append(fetchRanges, fetchRange{
			startOffset: off.value,
			endOffset:   off.value + 1,
			minBytes:    off.size,
			maxBytes:    off.size,
		})
	}

	// After generated fetch ranges from contiguous offsets, merge ranges to
	// minimize the number of ranges while maximizing usage of the tolerated
	// unused bytes.
	unusedBytes := int64(0)

	for unusedBytes < maxUnusedBytes && len(fetchRanges) > 1 {
		i, n := findMinUnusedRange(fetchRanges, avgSize)
		unusedBytes += n

		r1 := &fetchRanges[i-1]
		r2 := &fetchRanges[i]

		r1.endOffset = r2.endOffset
		r1.minBytes += r2.minBytes
		r1.maxBytes += r2.maxBytes + n

		copy(fetchRanges[i:], fetchRanges[i+1:])
		fetchRanges = fetchRanges[:len(fetchRanges)-1]
	}

	return fetchRanges
}

func findMinUnusedRange(fetchRanges []fetchRange, avgSize int64) (int, int64) {
	index := 0
	minMaxBytes := int64(0)
	minUnusedBytes := int64(math.MaxInt64)

	for i, r := range fetchRanges[1:] {
		maxBytes := r.maxBytes + fetchRanges[i].maxBytes
		unusedBytes := avgSize * (r.startOffset - fetchRanges[i].endOffset)
		// Select the two contiguous ranges with the smallest estimated
		// distance. If two range sequences are in equal distance, select
		// the one that would merge the smallest ranges (so we optimize for
		// reducing the number of small ranges).
		if unusedBytes < minUnusedBytes || (unusedBytes == minUnusedBytes && maxBytes < minMaxBytes) {
			index, minMaxBytes, minUnusedBytes = i+1, maxBytes, unusedBytes
		}
	}

	return index, minUnusedBytes
}
